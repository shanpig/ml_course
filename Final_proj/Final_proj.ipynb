{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:black; text-align:center; background-color:powderblue; padding:20px; margin:0\"> <b>期末專題 : 人臉濾鏡(來源為github 網頁)</b></h1>\n",
    "<h2 style=\"text-align:center; background-color:powderblue; padding:7px; margin:0\"> Resource : Akshay Chandra Lagandula, IIT Hyderabad </h2>\n",
    "<h3 style=\"text-align:center; background-color:powderblue; padding:7px; margin:0\"> github webpage : <a href=https://github.com/akshaychandra21/Selfie_Filters_OpenCV>https://github.com/akshaychandra21/Selfie_Filters_OpenCV</a></h3>\n",
    "<h4 style=\"text-align:center; background-color:powderblue; padding:7px; margin:0\">Editor : B05203008 廖哲宏</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:blue; font-size:120%\"><b>這是我的期末專題，由於我是一個人完成的，人力和時間上都比較吃緊，因此我決定改良一個簡單的人臉濾鏡。<br>我的程式架構來源如上所示，其原型僅能加上眼鏡，改良後可有不同的五官組合。</b></p>\n",
    "\n",
    "### ● 程式原理：\n",
    "1. 利用openCV結合網路攝影機，擷取串流影像並進行臉部偵測。\n",
    "2. 將偵測到的臉resize至96x96之tensor，而後作為15標記點之五官偵測的input。\n",
    "3. 利用事先 train 好的模型，predict出15個五官標記點。\n",
    "4. 藉由標記點進行圖層(眼睛、鼻子、嘴巴)的更換。\n",
    "5. 將編輯後的串流影像輸出。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"background-color:pink; padding:20px;margin:0\">1. Training model 的部分(此部分僅修改過method命名)</h2>\n",
    "<h2 style=\"background-color:pink; padding:20px;margin:0\">(我在remote server上跑，因此這裡沒有執行紀錄)</h2>\n",
    "<h3 style=\"background-color:pink; padding:20px;margin:0\">檔案原名:model_builder.py</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_data\n",
    "from my_CNN_model import *\n",
    "import cv2\n",
    "\n",
    "\n",
    "# Load training set\n",
    "X_train, y_train = load_data()\n",
    "\n",
    "# Set model layout\n",
    "my_model = create_CNN_model()\n",
    "\n",
    "# Compilt model\n",
    "compile_CNN_model(my_model, optimizer = 'adam', loss = 'mean_squared_error', metrics = ['accuracy'])\n",
    "\n",
    "# Training model\n",
    "hist = train_CNN_model(my_model, X_train, y_train)\n",
    "\n",
    "# Saving model\n",
    "save_CNN_model(my_model, 'my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"background-color:LightSalmon; padding:20px;margin:0\">2.Model layout(經修改後準確率從0.74.. 提升到0.82..)</h2>\n",
    "<h3 style=\"background-color:LightSalmon; padding:20px;margin:0\">檔案原名:my_CNN_model.py</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Dropout\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax, Nadam\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'                                           ####設定目標 GPU####\n",
    "\n",
    "def get_my_CNN_model_architecture():\n",
    "    '''\n",
    "    The network should accept a 96x96 grayscale image as input, and it should output a vector with 30 entries,\n",
    "    corresponding to the predicted (horizontal and vertical) locations of 15 facial keypoints.\n",
    "    '''\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, (5, 5), input_shape=(96,96,1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Convolution2D(32, (2, 2), activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(30))\n",
    "\n",
    "    return model;\n",
    "\n",
    "def compile_my_CNN_model(model, optimizer, loss, metrics):\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "def train_my_CNN_model(model, X_train, y_train):\n",
    "    return model.fit(X_train, y_train, epochs=100, batch_size=200, verbose=1, validation_split=0.2)\n",
    "\n",
    "def save_my_CNN_model(model, fileName):\n",
    "    model.save(fileName + '.h5')\n",
    "\n",
    "def load_my_CNN_model(fileName):\n",
    "    return load_model(fileName + '.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"background-color:Antiquewhite; padding:20px;margin:0\">3.訓練資料提取與前處理(此處並未修改)</h2>\n",
    "<h3 style=\"background-color:Antiquewhite; padding:20px;margin:0\">檔案原名:utils.py</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import load_model\n",
    "from pandas.io.parsers import read_csv\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def load_data(test=False):\n",
    "    \"\"\"\n",
    "    Loads data from FTEST if *test* is True, otherwise from FTRAIN.\n",
    "    Important that the files are in a `data` directory\n",
    "    \"\"\"\n",
    "    FTRAIN = 'data/training.csv'\n",
    "    FTEST = 'data/test.csv'\n",
    "    fname = FTEST if test else FTRAIN\n",
    "    df = read_csv(os.path.expanduser(fname))  # load dataframes\n",
    "\n",
    "    # The Image column has pixel values separated by space; convert\n",
    "    # the values to numpy arrays:\n",
    "    df['Image'] = df['Image'].apply(lambda im: np.fromstring(im, sep=' '))\n",
    "\n",
    "    df = df.dropna()  # drop all rows that have missing values in them\n",
    "\n",
    "    X = np.vstack(df['Image'].values) / 255.  # scale pixel values to [0, 1] (Normalizing)\n",
    "    X = X.astype(np.float32)\n",
    "    X = X.reshape(-1, 96, 96, 1) # return each images as 96 x 96 x 1\n",
    "\n",
    "    if not test:  # only FTRAIN has target columns\n",
    "        y = df[df.columns[:-1]].values\n",
    "        y = (y - 48) / 48  # scale target coordinates to [-1, 1] (Normalizing)\n",
    "        X, y = shuffle(X, y, random_state=42)  # shuffle train data\n",
    "        y = y.astype(np.float32)\n",
    "    else:\n",
    "        y = None\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"background-color:PaleGoldenRod; padding:20px;margin:0\">4. 濾鏡執行程式(大部分修改於此處，將原本只有墨鏡之濾鏡增加到五官)</h2>\n",
    "<h3 style=\"background-color:PaleGoldenRod; padding:20px;margin:0\">檔案原名:shader.py</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model complete\n",
      "load cascate complete\n"
     ]
    }
   ],
   "source": [
    "from my_CNN_model import *\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "\n",
    "# Load the model built in the previous step\n",
    "# 載入預先訓練好的模型\n",
    "my_model = load_CNN_model('./folder2/8481acc-8224valacc')\n",
    "print (\"load model complete\")\n",
    "\n",
    "# Face cascade to detect faces\n",
    "# 由 github提供之臉部偵測 xml檔\n",
    "face_cascade = cv2.CascadeClassifier('cascades/haarcascade_frontalface_default.xml')\n",
    "print (\"load cascate complete\")\n",
    "\n",
    "# Define the upper and lower boundaries for a color to be considered \"Blue\"\n",
    "# 定義碰到按鈕的藍色判斷範圍\n",
    "blueLower = np.array([100, 60, 60])\n",
    "blueUpper = np.array([140, 255, 255])\n",
    "\n",
    "# Define a 5x5 kernel for erosion and dilation\n",
    "# 用一個5x5convolution window\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "# Define filters'images/mask1.png', \n",
    "imgList = os.listdir(\"./images\")                       #將原本單一filter改為三種filter， -------------------------------#\n",
    "sunglassFilter = []                                     #每次觸碰 Next filter按鈕時隨機選取三種 filter                   # \n",
    "noseFilter = []                                                                                                        # \n",
    "mouthFilter = []                                                                                                       # \n",
    "for file in imgList:                                                                                                   #\n",
    "    if (file.startswith(\"sunglasses\")):                                                                                #\n",
    "        sunglassFilter.append(os.path.join(\"./images/\", file))                                                         #\n",
    "    elif (file.startswith(\"nose\")):                                                                                    #\n",
    "        noseFilter.append(os.path.join(\"./images/\", file))                                                             #\n",
    "    elif (file.startswith(\"mouth\")):                                                                                   #\n",
    "        mouthFilter.append(os.path.join(\"./images/\", file))                                                            #\n",
    "filtIdx1 = 0                                                                                                           # \n",
    "filtIdx2 = 0                                                                                                           # \n",
    "filtIdx3 = 0                                 ########################################################################### \n",
    "\n",
    "# Load the video\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "# Keep looping\n",
    "while (True):\n",
    "    # Grab the current paintWindow\n",
    "    (grabbed, frame) = camera.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame2 = np.copy(frame)\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Add the 'Next Filter' button to the frame\n",
    "    rec_x = 500\n",
    "    rec_y = 400\n",
    "    rec_w = 120\n",
    "    rec_h = 55\n",
    "    frame = cv2.rectangle(frame, (rec_x, rec_y), (rec_x + rec_w, rec_y + rec_h), (235,50,50), -1)\n",
    "    cv2.putText(frame, \"NEXT FILTER\", (rec_x+12, rec_y+27), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.25, 6)\n",
    "\n",
    "    # Determine which pixels fall within the blue boundaries and then blur the binary image\n",
    "    blueMask = cv2.inRange(hsv, blueLower, blueUpper)\n",
    "    blueMask = cv2.erode(blueMask, kernel, iterations=2)\n",
    "    blueMask = cv2.morphologyEx(blueMask, cv2.MORPH_OPEN, kernel)\n",
    "    blueMask = cv2.dilate(blueMask, kernel, iterations=1)\n",
    "\n",
    "    # Find contours (bottle cap in my case) in the image\n",
    "    (cnts, _) = cv2.findContours(blueMask.copy(), cv2.RETR_EXTERNAL,\n",
    "    \tcv2.CHAIN_APPROX_SIMPLE)\n",
    "    center = None\n",
    "\n",
    "    # Check to see if any contours were found\n",
    "    if len(cnts) > 0:\n",
    "    \t# Sort the contours and find the largest one -- we\n",
    "    \t# will assume this contour correspondes to the area of the bottle cap\n",
    "        cnt = sorted(cnts, key = cv2.contourArea, reverse = True)[0]\n",
    "        # Get the radius of the enclosing circle around the found contour\n",
    "        ((x, y), radius) = cv2.minEnclosingCircle(cnt)\n",
    "        # Draw the circle around the contour\n",
    "        cv2.circle(frame, (int(x), int(y)), int(radius), (0, 255, 255), 2)\n",
    "        # Get the moments to calculate the center of the contour (in this case Circle)\n",
    "        M = cv2.moments(cnt)\n",
    "        center = (int(M['m10'] / M['m00']), int(M['m01'] / M['m00']))\n",
    "\n",
    "        if rec_y <=center[1] <= (rec_y + rec_h):                             #每次觸碰按鈕，隨機生成三種 filter---------#\n",
    "            if rec_x <= center[0] <= (rec_x+rec_w): # Next Filter                                                     #\n",
    "                filtIdx1 = random.randint(0, len(sunglassFilter)-1)                                                   #\n",
    "                filtIdx2 = random.randint(0, len(noseFilter)-1)                                                       #\n",
    "                filtIdx3 = random.randint(0, len(mouthFilter)-1)                                                      #\n",
    "                continue                                                    ###########################################\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "\n",
    "        # Grab the face\n",
    "        gray_face = gray[y:y+h, x:x+w]\n",
    "        color_face = frame[y:y+h, x:x+w]\n",
    "        # Normalize to match the input format of the model - Range of pixel to [0, 1]\n",
    "        gray_normalized = gray_face / 255\n",
    "\n",
    "        # Resize it to 96x96 to match the input format of the model\n",
    "        original_shape = gray_face.shape # A Copy for future reference\n",
    "        face_resized = cv2.resize(gray_normalized, (96, 96), interpolation = cv2.INTER_AREA)\n",
    "        face_resized_copy = face_resized.copy()\n",
    "        face_resized = face_resized.reshape(1, 96, 96, 1)\n",
    "\n",
    "        # Predicting the keypoints using the model\n",
    "        keypoints = my_model.predict(face_resized)\n",
    "        \n",
    "        \n",
    "        # De-Normalize the keypoints values\n",
    "        keypoints = keypoints * 48 + 48\n",
    "\n",
    "        # Map the Keypoints back to the original image\n",
    "        face_resized_color = cv2.resize(color_face, (96, 96), interpolation = cv2.INTER_AREA)\n",
    "        face_resized_color2 = np.copy(face_resized_color)\n",
    "\n",
    "        # Pair them together\n",
    "        points = []\n",
    "        for i, co in enumerate(keypoints[0][0::2]):\n",
    "            points.append((co, keypoints[0][1::2][i]))\n",
    "        #print (\"points shape: {}\".format(points.shape))\n",
    "\n",
    "        # Add FILTER to the frame                                                #分別將三種 filter讀入-------------------#\n",
    "        filt1 = cv2.imread(sunglassFilter[filtIdx1], cv2.IMREAD_UNCHANGED)                                               #\n",
    "        filt2 = cv2.imread(noseFilter[filtIdx2], cv2.IMREAD_UNCHANGED)                                                   #\n",
    "        filt3 = cv2.imread(mouthFilter[filtIdx3], cv2.IMREAD_UNCHANGED)          #########################################  \n",
    "        \n",
    "        # centernter of face                                                     #加入兩眼中央之錨點位置方便定位------------#\n",
    "        center_x = int(round((points[0][0]+points[1][0])/2))                                                             #\n",
    "        center_y = int(round((points[0][1]+points[1][1])/2))                     #########################################\n",
    "        \n",
    "        x_start = 0\n",
    "        x_stop  = 0\n",
    "        y_start = 0\n",
    "        y_stop  = 0\n",
    "        \n",
    "        # for mouth                                                                ####更換嘴巴####\n",
    "        filt_width = int(math.floor((points[3][0]-points[5][0])*0.9/2))\n",
    "        filt_height = int(math.floor((points[14][1]-points[10][1])*0.7/2))\n",
    "        x_start = int(points[14][0]-filt_width)\n",
    "        x_stop  = int(points[14][0]+filt_width)\n",
    "        y_start = int(points[11][1]-filt_height)\n",
    "        y_stop  = int(points[11][1]+filt_height)\n",
    "        filt_resized = cv2.resize(filt3, (x_stop-x_start, y_stop-y_start))\n",
    "        transparent_region = filt_resized[:,:,:3] != 0\n",
    "        \n",
    "        if (face_resized_color[y_start:y_stop, x_start:x_stop,:].shape[0]== \\\n",
    "            filt_resized[:, :, :3].shape[0]):\n",
    "            face_resized_color[y_start:y_stop, x_start:x_stop,:][transparent_region]= \\\n",
    "            filt_resized[:,:,:3][transparent_region]\n",
    "        \n",
    "        else : \n",
    "            print (\"x: {}:{}, y: {}:{}, filt_resized : {}\\nface_resized_color[]: {}\".format(x_start, x_stop, y_start, y_stop, filt_resized[:, :, :3].shape, face_resized_color[y_start:y_stop, x_start:x_stop,:].shape))\n",
    "        \n",
    "        #for nose                                                                  ####更換鼻子####\n",
    "        filt_width = int(math.floor((points[0][0]-points[1][0])/2))\n",
    "        filt_height = int(math.floor((points[13][1]-center_y)*0.8/2))\n",
    "        x_start = center_x-filt_width\n",
    "        x_stop  = center_x+filt_width\n",
    "        y_start = center_y+int(0.3*filt_height)\n",
    "        y_stop  = center_y+int(2.3*filt_height)\n",
    "        filt_resized = cv2.resize(filt2, (x_stop-x_start, y_stop-y_start))\n",
    "        transparent_region = filt_resized[:,:,:3] != 0\n",
    "        if (filt_resized[:, :, :3].shape[0]==face_resized_color[y_start:y_stop, x_start:x_stop,:].shape[0]):\n",
    "            face_resized_color[y_start:y_stop, x_start:x_stop,:][transparent_region]= filt_resized[:,:,:3][transparent_region]\n",
    "        else : print (\"filt_resized : {}\\nface_resized_color[]: {}\".format(filt_resized[:, :, :3].shape, face_resized_color[y_start:y_stop, x_start:x_stop,:].shape))\n",
    "            \n",
    "        # for sunglasses                                                           ####更換眼鏡或眼睛####\n",
    "        filt_width = int(math.floor((points[7][0]-points[9][0])*1.1/2))\n",
    "        filt_height = int(math.floor((points[10][1]-points[8][1])*0.9/2))\n",
    "        x_start = center_x-filt_width\n",
    "        x_stop  = center_x+filt_width\n",
    "        y_start = center_y-filt_height\n",
    "        y_stop  = center_y+filt_height\n",
    "        filt_resized = cv2.resize(filt1, (x_stop-x_start, y_stop-y_start))\n",
    "        transparent_region = filt_resized[:,:,:3] != 0\n",
    "        \n",
    "        if (filt_resized[:, :, :3].shape[0]==face_resized_color[y_start:y_stop, x_start:x_stop,:].shape[0]):\n",
    "            face_resized_color[y_start:y_stop, x_start:x_stop,:][transparent_region]= filt_resized[:,:,:3][transparent_region]\n",
    "        else : print (\"filt_resized : {}\\nface_resized_color[]: {}\".format(filt_resized[:, :, :3].shape, face_resized_color[y_start:y_stop, x_start:x_stop,:].shape))\n",
    "\n",
    "            \n",
    "        # Resize the face_resized_color image back to its original shape\n",
    "        frame[y:y+h, x:x+w] = cv2.resize(face_resized_color, original_shape, interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "        # Add KEYPOINTS to the frame2\n",
    "        for keypoint in points:\n",
    "            cv2.circle(face_resized_color2, keypoint, 1, (0,255,0), 1)\n",
    "\n",
    "        frame2[y:y+h, x:x+w] = cv2.resize(face_resized_color2, original_shape, interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "        # Show the frame and the frame2\n",
    "        cv2.imshow(\"Selfie Filters\", frame)\n",
    "        cv2.imshow(\"Facial Keypoints\", frame2)\n",
    "\n",
    "    # If the 'q' key is pressed, stop the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Cleanup the camera and close any open windows\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"background-color:LightGrey; padding:20px; margin:0\">● 執行流程與結果</h2>\n",
    "<h3 style=\"background-color:LightGrey; padding:20px; margin:0\">執行my_CNN_model.py(2.)以及shader.py(4.)之後，串流影像即開始運作。<br><br>可看見兩視窗，右方視窗為經由model預測之標記點位置，左方視窗則為濾鏡效果(如下圖所示)。</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"1.png\" style=\"width:45%; float:left\">\n",
    "<img src=\"2.png\" style=\"width:45%; float:right\">\n",
    "<br>\n",
    "<img src=\"3.png\" style=\"width:45%; float:left\">\n",
    "<img src=\"4.png\" style=\"width:45%; float:right\">\n",
    "<br>\n",
    "<img src=\"5.png\" style=\"width:45%; float:left\">\n",
    "<img src=\"6.png\" style=\"width:45%; float:right\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
