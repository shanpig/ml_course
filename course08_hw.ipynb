{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 利用這次教的funcional API方式，測試一下對於 mnist data 若是先行提取部分特徵做訓練，而後再連回原始資料集進行第二次訓練，是否會影響其表現。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: KERAS_BACKEND=tensorflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%env KERAS_BACKEND=tensorflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基本的 load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heloo\n"
     ]
    }
   ],
   "source": [
    "print (\"Heloo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train0, y_train0), (x_test0, y_test0)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(60000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print (x_train0.shape)\n",
    "print (x_test0.shape)\n",
    "print (y_train0.shape)\n",
    "print (y_test0.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## x的部分做 reshape和 normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train0.reshape(len(x_train0[:, 0, 0]), x_train0[0].size)\n",
    "x_test = x_test0.reshape(len(x_test0[:, 0, 0]), x_test0[0].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print (x_train0.shape)\n",
    "print (x_test0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = (x_train-x_train.min())/(x_train.max()-x_train.min())\n",
    "x_test = (x_test-x_test.min())/(x_test.max()-x_test.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "print (x_train.max(), x_train.min())\n",
    "print (x_test.max(), x_test.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## y 做不同特徵之 labeling，共分三種：\n",
    "* 是偶數\n",
    "* 大於等於5\n",
    "* 可以被3整除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_iseven0=[]\n",
    "y_lt50=[]\n",
    "y_div30=[]\n",
    "for i in range(len(y_train0)):\n",
    "    # is even\n",
    "    if (y_train0[i]%2==0):\n",
    "        y_iseven0.append(1)\n",
    "    else : y_iseven0.append(0)\n",
    "        \n",
    "    # is > 5\n",
    "    if (y_train0[i]>=5):\n",
    "        y_lt50.append(1)\n",
    "    else : y_lt50.append(0)\n",
    "        \n",
    "    # is %3 == 0\n",
    "    if (y_train0[i]%3 == 0):\n",
    "        y_div30.append(1)\n",
    "    else : y_div30.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 1 9 2 1 3 1 4]\n",
      "[0, 1, 1, 0, 0, 1, 0, 0, 0, 1]\n",
      "[1, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "[0, 1, 0, 0, 1, 0, 0, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print (y_train0[:10])\n",
    "print (y_iseven0[:10])\n",
    "print (y_lt50[:10])\n",
    "print (y_div30[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 之後，y再進行 1-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train0, 10)\n",
    "y_test = to_categorical(y_test0, 10)\n",
    "\n",
    "y_iseven = to_categorical(y_iseven0, 2)\n",
    "y_lt5 = to_categorical(y_lt50, 2)\n",
    "y_div3 = to_categorical(y_div30, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print (y_train[:3])\n",
    "print (y_test[:3])\n",
    "print (y_iseven[:3])\n",
    "print (y_lt5[:3])\n",
    "print (y_div3[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 整個 Model 的 layout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第一步：\n",
    "利用branching 訓練一些數字特徵<br>\n",
    "![layout1](https://github.com/shanpig/ML-course/blob/master/layout1.png?raw=true)\n",
    "## 第二步：\n",
    "固定前面訓練結果，後面加上一層 NN，然後output出 1-hot結果<br>\n",
    "![layout2](https://github.com/shanpig/ML-course/blob/master/layout2.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model buildup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.layers import concatenate\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import Dense, Dropout, Activation, add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 各 functional 的 assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Input(shape=(784,))\n",
    "f1=Dense(20, kernel_initializer=\"random_uniform\", bias_initializer=\"zeros\", activation=\"sigmoid\")\n",
    "f2=Dense(2, kernel_initializer=\"random_uniform\", bias_initializer=\"zeros\", activation=\"sigmoid\")\n",
    "f3=Dense(2, kernel_initializer=\"random_uniform\", bias_initializer=\"zeros\", activation=\"sigmoid\")\n",
    "f4=Dense(2, kernel_initializer=\"random_uniform\", bias_initializer=\"zeros\", activation=\"sigmoid\")\n",
    "f5=Dense(20, kernel_initializer=\"random_uniform\", bias_initializer=\"zeros\", activation=\"sigmoid\")\n",
    "f6=Dense(10, kernel_initializer=\"random_uniform\", bias_initializer=\"zeros\", activation=\"softmax\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functional 及 neuron layers 之間的關係"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = f1(x)\n",
    "c1 = f2(h1)\n",
    "c2 = f3(h1)\n",
    "c3 = f4(h1)\n",
    "\n",
    "h = concatenate([c1, c2, c3, h1])\n",
    "\n",
    "h2 = f5(h)\n",
    "\n",
    "y = f6(h2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 設定兩步驟訓練的 list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout1 = [f1, f2, f3, f4]\n",
    "layout2 = [f5, f6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(x, y)\n",
    "model_iseven = Model(x, c1)\n",
    "model_lt5 = Model(x, c2)\n",
    "model_div3 = Model(x, c3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 784)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 20)           15700       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            42          dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            42          dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            42          dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 26)           0           dense_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 20)           540         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 10)           210         dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 16,576\n",
      "Trainable params: 16,576\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_iseven.compile(loss=\"categorical_crossentropy\", optimizer=Adam(), metrics=[\"acc\"])\n",
    "model_lt5.compile(loss=\"categorical_crossentropy\", optimizer=Adam(), metrics=[\"acc\"])\n",
    "model_div3.compile(loss=\"categorical_crossentropy\", optimizer=Adam(), metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"是偶數\"的model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.4166 - acc: 0.8435 - val_loss: 0.2815 - val_acc: 0.8932\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.2677 - acc: 0.8947 - val_loss: 0.2255 - val_acc: 0.9165\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.2060 - acc: 0.9249 - val_loss: 0.1708 - val_acc: 0.9410\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.1591 - acc: 0.9461 - val_loss: 0.1395 - val_acc: 0.9540\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.1323 - acc: 0.9555 - val_loss: 0.1222 - val_acc: 0.9592\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1153 - acc: 0.9610 - val_loss: 0.1114 - val_acc: 0.9630\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.1031 - acc: 0.9654 - val_loss: 0.1020 - val_acc: 0.9658\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 1s 21us/step - loss: 0.0944 - acc: 0.9680 - val_loss: 0.0978 - val_acc: 0.9668\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 1s 21us/step - loss: 0.0871 - acc: 0.9709 - val_loss: 0.0929 - val_acc: 0.9682\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 1s 20us/step - loss: 0.0809 - acc: 0.9725 - val_loss: 0.0871 - val_acc: 0.9705\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0758 - acc: 0.9745 - val_loss: 0.0847 - val_acc: 0.9708\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.0710 - acc: 0.9763 - val_loss: 0.0818 - val_acc: 0.9721\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 1s 20us/step - loss: 0.0671 - acc: 0.9777 - val_loss: 0.0803 - val_acc: 0.9726\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.0637 - acc: 0.9788 - val_loss: 0.0774 - val_acc: 0.9747\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 1s 21us/step - loss: 0.0603 - acc: 0.9804 - val_loss: 0.0765 - val_acc: 0.9744\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 1s 20us/step - loss: 0.0576 - acc: 0.9809 - val_loss: 0.0745 - val_acc: 0.9750\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.0549 - acc: 0.9817 - val_loss: 0.0729 - val_acc: 0.9756\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 1s 20us/step - loss: 0.0525 - acc: 0.9830 - val_loss: 0.0735 - val_acc: 0.9754\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.0504 - acc: 0.9837 - val_loss: 0.0719 - val_acc: 0.9759\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 1s 20us/step - loss: 0.0482 - acc: 0.9844 - val_loss: 0.0711 - val_acc: 0.9758\n"
     ]
    }
   ],
   "source": [
    "model_iseven_hist = model_iseven.fit(x_train, y_iseven, batch_size=128, epochs=20, shuffle=True, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"大於等於五\"的 model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 1s 31us/step - loss: 0.4962 - acc: 0.7773 - val_loss: 0.2949 - val_acc: 0.8991\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 1s 20us/step - loss: 0.2435 - acc: 0.9166 - val_loss: 0.1894 - val_acc: 0.9390\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.1768 - acc: 0.9404 - val_loss: 0.1505 - val_acc: 0.9511\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 1s 21us/step - loss: 0.1454 - acc: 0.9524 - val_loss: 0.1307 - val_acc: 0.9577\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.1268 - acc: 0.9583 - val_loss: 0.1181 - val_acc: 0.9618\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.1141 - acc: 0.9629 - val_loss: 0.1091 - val_acc: 0.9643\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.1044 - acc: 0.9660 - val_loss: 0.1045 - val_acc: 0.9651\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.0970 - acc: 0.9686 - val_loss: 0.0987 - val_acc: 0.9669\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.0908 - acc: 0.9704 - val_loss: 0.0949 - val_acc: 0.9672\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.0855 - acc: 0.9724 - val_loss: 0.0918 - val_acc: 0.9689\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 1s 21us/step - loss: 0.0810 - acc: 0.9742 - val_loss: 0.0895 - val_acc: 0.9686\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.0770 - acc: 0.9752 - val_loss: 0.0872 - val_acc: 0.9703\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.0736 - acc: 0.9762 - val_loss: 0.0854 - val_acc: 0.9706\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 1s 20us/step - loss: 0.0704 - acc: 0.9776 - val_loss: 0.0832 - val_acc: 0.9717\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.0675 - acc: 0.9784 - val_loss: 0.0822 - val_acc: 0.9719\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.0651 - acc: 0.9796 - val_loss: 0.0807 - val_acc: 0.9721\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 1s 21us/step - loss: 0.0627 - acc: 0.9807 - val_loss: 0.0791 - val_acc: 0.9732\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.0602 - acc: 0.9812 - val_loss: 0.0783 - val_acc: 0.9728\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.0582 - acc: 0.9819 - val_loss: 0.0769 - val_acc: 0.9728\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.0561 - acc: 0.9825 - val_loss: 0.0762 - val_acc: 0.9738\n"
     ]
    }
   ],
   "source": [
    "model_lt5_hist = model_lt5.fit(x_train, y_lt5, batch_size=128, epochs=20, shuffle=True, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"可被3整除\"的 model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 0.5414 - acc: 0.7190 - val_loss: 0.3579 - val_acc: 0.8808\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.2877 - acc: 0.9037 - val_loss: 0.2241 - val_acc: 0.9268\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.2092 - acc: 0.9291 - val_loss: 0.1792 - val_acc: 0.9400\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.1745 - acc: 0.9408 - val_loss: 0.1547 - val_acc: 0.9487\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.1529 - acc: 0.9483 - val_loss: 0.1405 - val_acc: 0.9530\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.1383 - acc: 0.9533 - val_loss: 0.1295 - val_acc: 0.9567\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.1271 - acc: 0.9565 - val_loss: 0.1261 - val_acc: 0.9568\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.1185 - acc: 0.9596 - val_loss: 0.1162 - val_acc: 0.9612\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.1114 - acc: 0.9626 - val_loss: 0.1111 - val_acc: 0.9630\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.1052 - acc: 0.9649 - val_loss: 0.1084 - val_acc: 0.9632\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.1002 - acc: 0.9662 - val_loss: 0.1060 - val_acc: 0.9637\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.0955 - acc: 0.9682 - val_loss: 0.1022 - val_acc: 0.9644\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.0915 - acc: 0.9694 - val_loss: 0.1002 - val_acc: 0.9653\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.0880 - acc: 0.9708 - val_loss: 0.0981 - val_acc: 0.9661\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.0851 - acc: 0.9722 - val_loss: 0.0970 - val_acc: 0.9670\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.0820 - acc: 0.9731 - val_loss: 0.0964 - val_acc: 0.9672\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.0795 - acc: 0.9739 - val_loss: 0.0945 - val_acc: 0.9671\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.0770 - acc: 0.9750 - val_loss: 0.0939 - val_acc: 0.9674\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.0746 - acc: 0.9756 - val_loss: 0.0927 - val_acc: 0.9679\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.0725 - acc: 0.9760 - val_loss: 0.0912 - val_acc: 0.9683\n"
     ]
    }
   ],
   "source": [
    "model_div3_hist = model_div3.fit(x_train, y_div3, batch_size=128, epochs=20, shuffle=True, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 將前面訓練過之參數鎖起來，接著訓練第二步。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 784)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 20)           15700       input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 2)            42          dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 2)            42          dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 2)            42          dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 6)            0           dense_27[0][0]                   \n",
      "                                                                 dense_28[0][0]                   \n",
      "                                                                 dense_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 26)           0           dense_26[0][0]                   \n",
      "                                                                 concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 20)           540         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 10)           210         dense_30[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 16,576\n",
      "Trainable params: 750\n",
      "Non-trainable params: 15,826\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in layout1:\n",
    "    i.trainable=False\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(), metrics=[\"acc\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第二步 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-495c10f98bf1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_hist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model_hist = model.fit(x_train, y_train, batch_size=128, epochs=20, shuffle=True, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 為了比對，另外做了兩層 fc layer 的對照 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(20, activation=\"sigmoid\", kernel_initializer=\"random_uniform\", bias_initializer=\"zeros\", input_dim = 784))\n",
    "model2.add(Dense(20, activation=\"sigmoid\", kernel_initializer=\"random_uniform\", bias_initializer=\"zeros\"))\n",
    "model2.add(Dense(10, activation=\"softmax\", kernel_initializer=\"random_uniform\", bias_initializer=\"zeros\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss=\"categorical_crossentropy\", metrics=[\"acc\"], optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_42 (Dense)             (None, 20)                15700     \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 16,330\n",
      "Trainable params: 16,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 2s 50us/step - loss: 1.9920 - acc: 0.3598 - val_loss: 1.4433 - val_acc: 0.5546\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 1.1844 - acc: 0.5995 - val_loss: 0.9862 - val_acc: 0.6395\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.8784 - acc: 0.6964 - val_loss: 0.7513 - val_acc: 0.7687\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.6832 - acc: 0.7998 - val_loss: 0.5879 - val_acc: 0.8369\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.5380 - acc: 0.8625 - val_loss: 0.4575 - val_acc: 0.8889\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.4207 - acc: 0.8985 - val_loss: 0.3700 - val_acc: 0.9082\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.3507 - acc: 0.9123 - val_loss: 0.3240 - val_acc: 0.9186\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.3077 - acc: 0.9208 - val_loss: 0.2966 - val_acc: 0.9226\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.2767 - acc: 0.9289 - val_loss: 0.2739 - val_acc: 0.9269\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.2527 - acc: 0.9344 - val_loss: 0.2555 - val_acc: 0.9300\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.2339 - acc: 0.9378 - val_loss: 0.2448 - val_acc: 0.9317\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.2187 - acc: 0.9410 - val_loss: 0.2350 - val_acc: 0.9341\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.2061 - acc: 0.9439 - val_loss: 0.2269 - val_acc: 0.9354\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1953 - acc: 0.9467 - val_loss: 0.2193 - val_acc: 0.9369\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.1861 - acc: 0.9490 - val_loss: 0.2136 - val_acc: 0.9385\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.1777 - acc: 0.9500 - val_loss: 0.2086 - val_acc: 0.9391\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1708 - acc: 0.9525 - val_loss: 0.2041 - val_acc: 0.9418\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.1642 - acc: 0.9539 - val_loss: 0.2002 - val_acc: 0.9425\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.1580 - acc: 0.9552 - val_loss: 0.1991 - val_acc: 0.9433\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.1529 - acc: 0.9565 - val_loss: 0.1960 - val_acc: 0.9440\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e85193a198>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train, y_train, batch_size=128, epochs=20, shuffle=True, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 兩 model 對同一測資的 accuracy比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 60us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3425723619103432, 0.8949]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 23us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.19678768182098866, 0.9459]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 看起來反而是兩層 fc 比較準，倒是出乎我意料之外XDDD"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
